#!/usr/bin/env python3
"""
LangChain compatibility layer for our test suite
Shows how to adapt LangChain components to pass our custom tests
"""

import asyncio
import tempfile
from pathlib import Path
from typing import List, Dict, Any, Optional
import numpy as np

# Mock LangChain imports (these would be real with LangChain installed)
class MockLangChainComponent:
    """Mock LangChain component for demonstration"""
    def __init__(self, **kwargs):
        self.config = kwargs

# Our custom interfaces
from rag_service.exceptions import DocumentProcessingError, RetrievalError, QAError


class LangChainDocumentProcessor:
    """
    Adapter that makes LangChain document processing compatible with our tests
    """
    
    def __init__(self):
        # These would be real LangChain components:
        # from langchain.text_splitter import RecursiveCharacterTextSplitter
        # from langchain.document_loaders import TextLoader, PyPDFLoader
        self.text_splitter = MockLangChainComponent(chunk_size=1000, chunk_overlap=200)
        self.text_loader = MockLangChainComponent()
        self.pdf_loader = MockLangChainComponent()
    
    def process_file(self, file_path: str) -> Dict[str, Any]:
        """Process a file - compatible with our test interface"""
        try:
            if not Path(file_path).exists():
                raise DocumentProcessingError(f"File not found: {file_path}")
            
            # Check file size
            file_size = Path(file_path).stat().st_size
            if file_size == 0:
                raise DocumentProcessingError("Empty file")
            
            # Check file type
            suffix = Path(file_path).suffix.lower()
            if suffix not in ['.txt', '.pdf']:
                raise DocumentProcessingError(f"Unsupported file type: {suffix}")
            
            # Read content (simplified)
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract metadata
            metadata = self.extract_metadata(file_path)
            
            return {
                'content': content,
                'metadata': metadata
            }
            
        except Exception as e:
            if isinstance(e, DocumentProcessingError):
                raise
            raise DocumentProcessingError(f"Failed to process file: {str(e)}")
    
    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """Chunk text - compatible with our test interface"""
        if not text:
            return []
        
        chunks = []
        start = 0
        
        while start < len(text):
            # Calculate end position
            end = min(start + chunk_size, len(text))
            
            # Extract chunk
            chunk = text[start:end]
            chunks.append(chunk)
            
            # Move start position (with overlap)
            start = end - overlap
            if start >= len(text):
                break
        
        return chunks
    
    def extract_metadata(self, file_path: str) -> Dict[str, Any]:
        """Extract metadata - compatible with our test interface"""
        path = Path(file_path)
        return {
            'filename': path.name,
            'file_size': path.stat().st_size,
            'file_type': path.suffix.lower(),
            'created_at': path.stat().st_ctime
        }


class LangChainVectorStore:
    """
    Adapter that makes LangChain vector store compatible with our tests
    """
    
    def __init__(self, dimension: int = 384):
        # This would be: from langchain.vectorstores import Chroma
        self.dimension = dimension
        self.documents = {}
        self.embeddings = {}
    
    def add_documents(self, documents: List[Dict[str, Any]], embeddings: List[np.ndarray]):
        """Add documents - compatible with our test interface"""
        for doc, embedding in zip(documents, embeddings):
            doc_id = doc.get('id', str(len(self.documents)))
            self.documents[doc_id] = doc
            self.embeddings[doc_id] = embedding
    
    def similarity_search(self, query_embedding: np.ndarray, k: int = 5) -> List[Dict[str, Any]]:
        """Search for similar documents - compatible with our test interface"""
        if not self.embeddings:
            return []
        
        # Calculate similarities (simplified)
        similarities = []
        for doc_id, doc_embedding in self.embeddings.items():
            # Cosine similarity
            similarity = np.dot(query_embedding, doc_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
            )
            similarities.append({
                'document': self.documents[doc_id],
                'score': float(similarity)
            })
        
        # Sort by similarity and return top k
        similarities.sort(key=lambda x: x['score'], reverse=True)
        return similarities[:k]
    
    def get_document(self, doc_id: str) -> Optional[Dict[str, Any]]:
        """Get document by ID - compatible with our test interface"""
        return self.documents.get(doc_id)
    
    def delete_document(self, doc_id: str):
        """Delete document - compatible with our test interface"""
        if doc_id in self.documents:
            del self.documents[doc_id]
            del self.embeddings[doc_id]
    
    def update_document(self, document: Dict[str, Any], embedding: np.ndarray):
        """Update document - compatible with our test interface"""
        doc_id = document.get('id')
        if doc_id:
            self.documents[doc_id] = document
            self.embeddings[doc_id] = embedding
    
    def count(self) -> int:
        """Count documents - compatible with our test interface"""
        return len(self.documents)
    
    def cleanup(self):
        """Cleanup resources - compatible with our test interface"""
        self.documents.clear()
        self.embeddings.clear()


class LangChainRetriever:
    """
    Adapter that makes LangChain retriever compatible with our tests
    """
    
    def __init__(self, vector_store: LangChainVectorStore, embedder, k: int = 5, threshold: float = 0.0):
        self.vector_store = vector_store
        self.embedder = embedder
        self.k = k
        self.threshold = threshold
    
    async def retrieve(self, query: str, **kwargs) -> List[Dict[str, Any]]:
        """Retrieve documents - compatible with our test interface"""
        try:
            # Override parameters from kwargs
            k = kwargs.get('k', self.k)
            threshold = kwargs.get('threshold', self.threshold)
            
            # Get query embedding
            query_embedding = self.embedder.embed_query(query)
            
            # Search similar documents
            results = self.vector_store.similarity_search(query_embedding, k=k)
            
            # Filter by threshold
            filtered_results = [
                result for result in results 
                if result['score'] >= threshold
            ]
            
            return filtered_results
            
        except Exception as e:
            raise RetrievalError(f"Failed to retrieve documents: {str(e)}")


class LangChainQAService:
    """
    Adapter that makes LangChain QA compatible with our tests
    """
    
    def __init__(self, llm):
        self.llm = llm
    
    def format_context(self, context: List[Dict[str, Any]]) -> str:
        """Format context - compatible with our test interface"""
        if not context:
            return "No relevant context found."
        
        formatted_parts = []
        for i, doc in enumerate(context, 1):
            content = doc.get('content', '')
            source = doc.get('metadata', {}).get('source', 'Unknown source')
            formatted_parts.append(f"[{i}] {content} (Source: {source})")
        
        return "\n".join(formatted_parts)
    
    async def generate_answer(self, query: str, context: List[Dict[str, Any]]) -> str:
        """Generate answer - compatible with our test interface"""
        try:
            # Format context
            formatted_context = self.format_context(context)
            
            # Create prompt
            prompt = f"""
            Context: {formatted_context}
            
            Question: {query}
            
            Answer:
            """
            
            # Generate answer using LLM
            answer = await self.llm.generate(prompt)
            return answer
            
        except Exception as e:
            raise QAError(f"Failed to generate answer: {str(e)}")
    
    async def generate_answer_with_sources(self, query: str, context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate answer with sources - compatible with our test interface"""
        try:
            # Generate answer
            answer = await self.generate_answer(query, context)
            
            # Extract sources
            sources = []
            seen_sources = set()
            
            for doc in context:
                source = doc.get('metadata', {}).get('source', 'Unknown source')
                if source not in seen_sources:
                    sources.append(source)
                    seen_sources.add(source)
            
            return {
                'answer': answer,
                'sources': sources
            }
            
        except Exception as e:
            raise QAError(f"Failed to generate answer with sources: {str(e)}")


class LangChainRAGPipeline:
    """
    Adapter that makes LangChain RAG pipeline compatible with our tests
    """
    
    def __init__(self, **kwargs):
        # Initialize components
        self.document_processor = LangChainDocumentProcessor()
        self.vector_store = LangChainVectorStore()
        self.embedder = MockLangChainComponent()  # Would be HuggingFaceEmbeddings
        self.retriever = LangChainRetriever(self.vector_store, self.embedder)
        self.qa_service = LangChainQAService(MockLangChainComponent())
    
    def ingest_document(self, file_path: str) -> Dict[str, Any]:
        """Ingest document - compatible with our test interface"""
        try:
            # Process document
            processed = self.document_processor.process_file(file_path)
            
            # Chunk text
            chunks = self.document_processor.chunk_text(processed['content'])
            
            # Create document objects
            documents = []
            for i, chunk in enumerate(chunks):
                doc = {
                    'id': f"{file_path}_{i}",
                    'content': chunk,
                    'metadata': {
                        **processed['metadata'],
                        'chunk_index': i
                    }
                }
                documents.append(doc)
            
            # Generate embeddings (mocked)
            embeddings = [np.random.rand(384).astype(np.float32) for _ in chunks]
            
            # Add to vector store
            self.vector_store.add_documents(documents, embeddings)
            
            return {
                'chunks_created': len(chunks),
                'status': 'success'
            }
            
        except Exception as e:
            raise DocumentProcessingError(f"Failed to ingest document: {str(e)}")
    
    async def query(self, query: str, **kwargs) -> Dict[str, Any]:
        """Query the RAG system - compatible with our test interface"""
        try:
            # Retrieve relevant documents
            retrieved_docs = await self.retriever.retrieve(query, **kwargs)
            
            # Extract context
            context = [doc['document'] for doc in retrieved_docs]
            
            # Generate answer with sources
            result = await self.qa_service.generate_answer_with_sources(query, context)
            
            return {
                'answer': result['answer'],
                'sources': result['sources'],
                'retrieved_documents': len(retrieved_docs)
            }
            
        except Exception as e:
            raise QAError(f"Failed to query RAG system: {str(e)}")
    
    def cleanup(self):
        """Cleanup resources - compatible with our test interface"""
        self.vector_store.cleanup()


# Test compatibility
async def test_langchain_compatibility():
    """Test that LangChain adapters work with our test patterns"""
    
    print("ðŸ”— Testing LangChain Compatibility")
    print("=" * 40)
    
    # Create test document
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        f.write("Paris is the capital of France. France is in Europe.")
        test_file = f.name
    
    try:
        # Test document processing
        processor = LangChainDocumentProcessor()
        result = processor.process_file(test_file)
        assert 'content' in result
        assert 'metadata' in result
        print("âœ… Document processing compatible")
        
        # Test chunking
        chunks = processor.chunk_text(result['content'], chunk_size=50, overlap=10)
        assert len(chunks) > 0
        print("âœ… Text chunking compatible")
        
        # Test vector store
        vector_store = LangChainVectorStore()
        documents = [{'id': 'test', 'content': 'test content', 'metadata': {'source': 'test'}}]
        embeddings = [np.random.rand(384).astype(np.float32)]
        vector_store.add_documents(documents, embeddings)
        assert vector_store.count() == 1
        print("âœ… Vector store compatible")
        
        # Test RAG pipeline
        pipeline = LangChainRAGPipeline()
        ingest_result = pipeline.ingest_document(test_file)
        assert 'chunks_created' in ingest_result
        print("âœ… RAG pipeline ingestion compatible")
        
        query_result = await pipeline.query("What is the capital of France?")
        assert 'answer' in query_result
        assert 'sources' in query_result
        print("âœ… RAG pipeline query compatible")
        
        print("\nðŸŽ‰ All compatibility tests passed!")
        print("The LangChain implementation WOULD pass our test suite!")
        
    finally:
        # Cleanup
        Path(test_file).unlink()


if __name__ == "__main__":
    asyncio.run(test_langchain_compatibility())
